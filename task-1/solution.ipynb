{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as PySQL\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from random import randint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "#   GLOBALS   #\n",
    "###############\n",
    "SHINGLE_SIZE = 5\n",
    "BAND_SIZE    = 20\n",
    "ROW_SIZE     = 5\n",
    "\n",
    "GCLOUD = False\n",
    "\n",
    "# Spark\n",
    "SPARK = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"spark://master:7077\" if GCLOUD else \"local[*]\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .appName(\"PDD-Big-Task-1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Shingles\n",
    "SHINGLE_BASE = ord(\"Z\") - ord(\"A\") + 1\n",
    "\n",
    "# Minhash\n",
    "HASH_MOD = 1_000_000_007\n",
    "PERMUTATION_COUNT = BAND_SIZE * ROW_SIZE\n",
    "RAND_MAX = (2 ** 32) - 1\n",
    "PERMUTATION_ARR_BROADCAST = SPARK.sparkContext.broadcast(\n",
    "    np.array([\n",
    "        (randint(1, RAND_MAX), randint(0, RAND_MAX))\n",
    "        for _ in range(PERMUTATION_COUNT)\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Group definition file\n",
    "GROUP_DEFINITION_PATH   = \"hdfs://master:9000/data/group_definition.json\" if GCLOUD else \"data/group_definition.json\"\n",
    "GROUP_DEFINITION_SCHEMA = StructType([\n",
    "    StructField(\"group\", StringType(), False),\n",
    "    StructField(\"protein_list\", ArrayType(StringType(), False), False)\n",
    "])\n",
    "\n",
    "# Fasta directory\n",
    "FASTA_PATH   = \"hdfs://master:9000/data/fasta\" if GCLOUD else \"data/fasta\"\n",
    "FASTA_SCHEMA = StructType([\n",
    "    StructField(\"name\", StringType(), False),\n",
    "    StructField(\"value\", StringType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#   HELPER FUNCTIONS   #\n",
    "########################\n",
    "def loadDataFrameGroupDefinition():\n",
    "    df_group_definition_flat = SPARK.read.json(GROUP_DEFINITION_PATH)\n",
    "    return df_group_definition_flat.melt([], df_group_definition_flat.columns, \"group\", \"protein_list\")\n",
    "\n",
    "def loadDataFrameFasta():\n",
    "    return SPARK.read.schema(FASTA_SCHEMA).json(FASTA_PATH)\n",
    "\n",
    "def shingle_int(shingle):\n",
    "    return sum(\n",
    "        (ord(aminoacid) - ord(\"A\")) * (SHINGLE_BASE ** exp)\n",
    "        for exp, aminoacid in enumerate(shingle[::-1])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "#   MINHASH UDF   #\n",
    "###################\n",
    "def getMinhashesOfBands(value):\n",
    "    shingle_int_arr = np.array([\n",
    "        shingle_int(value[i : i + SHINGLE_SIZE])\n",
    "        for i in range(len(value) - SHINGLE_SIZE + 1)\n",
    "    ])\n",
    "\n",
    "    signature_arr = np.array([\n",
    "        np.min((a * shingle_int_arr + b) % HASH_MOD)\n",
    "        for a, b in PERMUTATION_ARR_BROADCAST.value\n",
    "    ])\n",
    "\n",
    "    signature_batch_hash_arr = np.array([\n",
    "        hash(tuple(signature_arr[i : i + ROW_SIZE]))\n",
    "        for i in range(0, PERMUTATION_COUNT, ROW_SIZE)\n",
    "    ])\n",
    "\n",
    "    return enumerate(signature_batch_hash_arr.tolist())\n",
    "\n",
    "minhash_tuple_type = StructType([\n",
    "    StructField(\"minhash_id\", IntegerType(), False),\n",
    "    StructField(\"minhash_value\", IntegerType(), False)\n",
    "])\n",
    "\n",
    "udf_get_minhashes_of_bands = PySQL.udf(getMinhashesOfBands, ArrayType(minhash_tuple_type,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "#   DATA FRAMES   #\n",
    "###################\n",
    "\n",
    "df_group_definition = loadDataFrameGroupDefinition()\n",
    "df_fasta = loadDataFrameFasta()\n",
    "\n",
    "# Process group definition data\n",
    "df_group_statistics = df_group_definition \\\n",
    "    .withColumn(\n",
    "        \"group_count\",\n",
    "        (PySQL.size(PySQL.col(\"protein_list\"))).cast(LongType())\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"group_pairs\",\n",
    "        (PySQL.col(\"group_count\") * (PySQL.col(\"group_count\") - 1) / 2).cast(LongType())\n",
    "    ) \\\n",
    "    .select(\"group\", \"group_count\", \"group_pairs\")\n",
    "\n",
    "protein_count_total = df_group_statistics \\\n",
    "    .agg(PySQL.sum(\"group_count\").alias(\"protein_count_sum\")) \\\n",
    "    .collect()[0][\"protein_count_sum\"]\n",
    "\n",
    "df_group_statistics = df_group_statistics \\\n",
    "    .withColumn(\n",
    "        \"mixed_pairs\",\n",
    "        PySQL.col(\"group_count\") * (protein_count_total - PySQL.col(\"group_count\"))\n",
    "    ) \\\n",
    "    .select(\"group\", \"group_count\", \"group_pairs\", \"mixed_pairs\")\n",
    "\n",
    "df_proteins = df_group_definition \\\n",
    "    .select(\"group\", PySQL.explode(\"protein_list\").alias(\"protein\"))\n",
    "\n",
    "# LSH DF\n",
    "df_lsh = df_fasta \\\n",
    "    .withColumn(\"minhash_band_signature_list\", udf_get_minhashes_of_bands(\"value\")) \\\n",
    "    .select(\"name\", \"minhash_band_signature_list\") \\\n",
    "    .join(df_proteins, df_fasta.name == df_proteins.protein, \"left\") \\\n",
    "    .select(\"group\", \"name\", PySQL.explode(\"minhash_band_signature_list\").alias(\"minhash\"))\n",
    "\n",
    "# Similarity DF\n",
    "df_similarity = df_lsh.alias(\"df_1\") \\\n",
    "    .join(\n",
    "        df_lsh.alias(\"df_2\"),\n",
    "        (PySQL.col(\"df_1.minhash\") == PySQL.col(\"df_2.minhash\")) & \\\n",
    "            (PySQL.col(\"df_1.name\") < PySQL.col(\"df_2.name\")),\n",
    "        \"inner\"\n",
    "    ) \\\n",
    "    .select(\n",
    "        PySQL.col(\"df_1.group\").alias(\"group_1\"),\n",
    "        PySQL.col(\"df_2.group\").alias(\"group_2\"),\n",
    "        PySQL.col(\"df_1.name\").alias(\"name_1\"),\n",
    "        PySQL.col(\"df_2.name\").alias(\"name_2\"),\n",
    "        PySQL.col(\"df_1.minhash\").alias(\"minhash\")\n",
    "    ) \\\n",
    "    .dropDuplicates([\"group_1\", \"group_2\", \"name_1\", \"name_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "#   STATISTICS   #\n",
    "##################\n",
    "true_positive_total = df_similarity \\\n",
    "    .filter(PySQL.col(\"group_1\") == PySQL.col(\"group_2\")) \\\n",
    "    .count()\n",
    "\n",
    "false_positive_total = df_similarity \\\n",
    "    .filter(PySQL.col(\"group_1\") != PySQL.col(\"group_2\")) \\\n",
    "    .count()\n",
    "\n",
    "single_group_pairs_total = df_group_statistics \\\n",
    "    .agg(PySQL.sum(\"group_pairs\").alias(\"group_pairs_sum\")) \\\n",
    "    .collect()[0][\"group_pairs_sum\"]\n",
    "\n",
    "mixed_group_pairs_total = df_group_statistics \\\n",
    "    .agg(PySQL.sum(\"mixed_pairs\").alias(\"mixed_pairs_sum\")) \\\n",
    "    .collect()[0][\"mixed_pairs_sum\"] \\\n",
    "    // 2\n",
    "\n",
    "print(f\"No. of true positive pairs:  {true_positive_total}\")\n",
    "print(f\"No. of false positive pairs: {false_positive_total}\")\n",
    "print(f\"No. of single group pairs:   {single_group_pairs_total}\")\n",
    "print(f\"No. of mixed group pairs:    {mixed_group_pairs_total}\")\n",
    "print()\n",
    "\n",
    "true_positive_rate  = true_positive_total  / single_group_pairs_total\n",
    "false_positive_rate = false_positive_total / mixed_group_pairs_total\n",
    "precision           = true_positive_total  / (true_positive_total + false_positive_total)\n",
    "\n",
    "print(f\"True positive rate:  {true_positive_rate}\")\n",
    "print(f\"False positive rate: {false_positive_rate}\")\n",
    "print(f\"Precision:           {precision}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
