{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip --quiet\n",
    "%pip install pyspark --quiet\n",
    "%pip install -U -q PyDrive --quiet\n",
    "%pip install numpy pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALA_VERSION = \"2.12\"\n",
    "KAFKA_VERSION = \"3.7.0\"\n",
    "PYSPARK_SCALA_VERSION = \"2.12\"\n",
    "SPARK_VERSION = \"3.5.1\"\n",
    "\n",
    "%env SCALA_VERSION=$SCALA_VERSION\n",
    "%env KAFKA_VERSION=$KAFKA_VERSION\n",
    "%env PYSPARK_SCALA_VERSION=$PYSPARK_SCALA_VERSION\n",
    "%env SPARK_VERSION=$SPARK_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./start-kafka.sh\n",
    "!tail -n 100 kafka/logs/server.log | grep -i \"Kafka Server started\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC1 = \"topic1\"\n",
    "TOPIC2 = \"topic2\"\n",
    "BOOTSTRAP_SERVER = \"127.0.0.1:9092\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./create-topics.sh {BOOTSTRAP_SERVER} {TOPIC1} {TOPIC2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env TOPIC1=$TOPIC1\n",
    "%env TOPIC2=$TOPIC2\n",
    "%env BOOTSTRAP_SERVER=$BOOTSTRAP_SERVER\n",
    "!rm -rf generator.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash --bg --proc data_producer_script --out data_producer_output --err data_producer_error\n",
    "echo \"Starting data producer\"\n",
    "bash populate-topics.sh --topic1 $TOPIC1 --topic2 $TOPIC2 --bootstrap_server $BOOTSTRAP_SERVER\n",
    "sleep 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "packages = [\n",
    "    f'org.apache.spark:spark-sql-kafka-0-10_{PYSPARK_SCALA_VERSION}:{SPARK_VERSION}',\n",
    "    f'org.apache.kafka:kafka-clients:{KAFKA_VERSION}'\n",
    "]\n",
    "# scc.stop(); spark.stop()\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", \",\".join(packages)) \\\n",
    "    .appName(\"PDD task-2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "scc = StreamingContext(spark.sparkContext, 2)\n",
    "\n",
    "# import json\n",
    "#\n",
    "# print(json.dumps({kv[0]: kv[1] for kv in spark.sparkContext.getConf().getAll()}, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash kafka/bin/kafka-console-consumer.sh --topic {TOPIC1} --max-messages 10 --bootstrap-server {BOOTSTRAP_SERVER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "df = spark.readStream.format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"127.0.0.1:9092\") \\\n",
    "  .option(\"subscribe\", \"topic1\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (\n",
    "    df.select(F.col(\"*\"))\n",
    "    .writeStream\n",
    "    .outputMode(\"update\")\n",
    "    .format(\"console\")\n",
    "    .foreachBatch(lambda df, b: df.show())\n",
    "    .start()\n",
    ")\n",
    "\n",
    "x.awaitTermination(10)\n",
    "x.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_producer_script.kill()\n",
    "# scc.stop()\n",
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
